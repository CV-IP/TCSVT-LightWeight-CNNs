{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Denoising_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv9RI8SsxYeN",
        "colab_type": "text"
      },
      "source": [
        "A Sample Notebook for realizing proposed compressed version of DnCNN framework\n",
        "for image denoising."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZk2K1bsxTW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import h5py\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from skimage.measure.simple_metrics import compare_psnr\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "from network import DnCNN, DnCNN_cheap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg7ouwIpxTW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_PSNR(img, imclean, data_range):\n",
        "    Img = img.data.cpu().numpy().astype(np.float32)\n",
        "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        "    PSNR = 0\n",
        "    for i in range(Img.shape[0]):\n",
        "        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
        "    return (PSNR/Img.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeqxDL1IxTXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.train = train\n",
        "        # Store images in .h5 file format\n",
        "        if self.train:\n",
        "            h5f = h5py.File('train.h5', 'r')\n",
        "        else:\n",
        "            h5f = h5py.File('val.h5', 'r')\n",
        "        self.keys = list(h5f.keys())\n",
        "        random.shuffle(self.keys)\n",
        "        h5f.close()\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            h5f = h5py.File('train.h5', 'r')\n",
        "        else:\n",
        "            h5f = h5py.File('val.h5', 'r')\n",
        "        key = self.keys[index]\n",
        "        data = np.array(h5f[key])\n",
        "        h5f.close()\n",
        "        return torch.Tensor(data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDWTN7qYxTXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noiseL=25\n",
        "learning_rate=0.001\n",
        "batchSize=64\n",
        "print('Loading dataset ...\\n')\n",
        "dataset_train = Dataset(train=True)\n",
        "dataset_val = Dataset(train=False)\n",
        "loader_train = DataLoader(dataset=dataset_train, num_workers=7, \n",
        "                          batch_size=batchSize, shuffle=True)\n",
        "model = DnCNN_cheap() # DnCNN()\n",
        "model=model.cuda()\n",
        "criterion = nn.MSELoss(size_average=False)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "best_val=0 \n",
        "\n",
        "for epoch in range(50):\n",
        "    test_loss = 0\n",
        "    epoch_loss = 0\n",
        "    for i, data in enumerate(loader_train, 0):\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "        img_train = data\n",
        "        noise = torch.FloatTensor(img_train.size()).normal_(mean=0, std=noiseL/255.)\n",
        "        imgn_train = img_train + noise\n",
        "        img_train, imgn_train = Variable(img_train.cuda()), Variable(imgn_train.cuda())\n",
        "        noise = Variable(noise.cuda())\n",
        "        out_train = model(imgn_train)\n",
        "        loss = criterion(out_train, noise) / (img_train.size()[0]*2)\n",
        "        psnr_train = batch_PSNR(imgn_train-out_train, img_train, 1.)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss = epoch_loss+loss.item()\n",
        "        # results\n",
        "        if i%30 == 0:\n",
        "             print(\"[epoch %d][%d/%d] loss: %.4f PSNR_train: %.4f\" %\n",
        "                  (epoch+1, i+1, len(loader_train), loss.item(), psnr_train))\n",
        "    model.eval()\n",
        "    epoch_loss=epoch_loss/len(loader_train)\n",
        "    psnr_val = 0\n",
        "    for k in range(len(dataset_val)):\n",
        "        img_val = torch.unsqueeze(dataset_val[k], 0)\n",
        "        noise = torch.FloatTensor(img_val.size()).normal_(mean=0, std=noiseL/255.)\n",
        "        imgn_val = img_val + noise\n",
        "        img_val, imgn_val = Variable(img_val.cuda()), Variable(imgn_val.cuda())\n",
        "        with torch.no_grad():\n",
        "          out_val = torch.clamp(imgn_val-model(imgn_val), 0., 1.)\n",
        "        psnr_val += batch_PSNR(out_val, img_val, 1.)\n",
        "        test_loss += criterion(out_val, img_val) / (imgn_train.size()[0]*2)\n",
        "    psnr_val /= len(dataset_val)\n",
        "    test_loss /= len(dataset_val)\n",
        "    print(\"[epoch %d] Train Loss: %.4f Val Loss: %.4f PSNR_val: %.4f\" %\n",
        "                  (epoch+1, epoch_loss,test_loss.item(), psnr_val))\n",
        "    \n",
        "    if epoch%10==0:\n",
        "        learning_rate=learning_rate*0.5\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = learning_rate\n",
        "            \n",
        "    if psnr_val>=best_val:\n",
        "        torch.save(model.state_dict(),'model.pth')\n",
        "        best_val=psnr_val "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}